{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import concurrent.futures\n",
    "\n",
    "MAX_THREADS = 30\n",
    "\n",
    "def construct_url(team_id, season_id):\n",
    "    url = f'https://www.soccerbase.com/teams/team.sd?team_id={team_id}&teamTabs=stats&season_id={season_id}'\n",
    "    return url\n",
    "\n",
    "def get_season_urls():\n",
    "    team_id = 2598\n",
    "    season_id = 155\n",
    "\n",
    "    url = construct_url(team_id, season_id)\n",
    "    r = requests.get(url)\n",
    "    doc = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    season_list = doc.select('#statsSeasonSelectTop option')\n",
    "    season_ids = [construct_url(team_id, season[\"value\"]) for season in season_list[1:]]\n",
    "\n",
    "    return season_ids\n",
    "\n",
    "def get_player_list(url):\n",
    "    session = requests.Session()\n",
    "    r = session.get(url)\n",
    "    doc = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    season = doc.select_one('.seasonSelector h3').text\n",
    "    player_list = doc.select('table.center tbody tr')\n",
    "\n",
    "    all_players = []\n",
    "    for player in player_list:\n",
    "        player_info = player.select_one('.first')\n",
    "\n",
    "        player_name = player_info.get_text()\n",
    "        player_name = player_name.split('(')\n",
    "        player_name = player_name[0]\n",
    "        player_name = player_name.strip()\n",
    "    \n",
    "        player_url = player_info.select_one('a')['href']\n",
    "        player_url = f\"https://www.soccerbase.com{player_url}\"\n",
    "\n",
    "        player_id = player_url.split(\"=\")[1]\n",
    "\n",
    "        all_players.append({\n",
    "            \"player_id\": player_id,\n",
    "            \"player_name\": player_name,\n",
    "            \"player_url\": player_url\n",
    "        })\n",
    "    return all_players\n",
    "\n",
    "def get_player_career(player_dict):\n",
    "    player_id = player_dict[\"player_id\"]\n",
    "    player_name = player_dict[\"player_name\"]\n",
    "    url = player_dict[\"player_url\"]\n",
    "\n",
    "    session = requests.Session()\n",
    "    r = session.get(url)\n",
    "    \n",
    "    career = pd.read_html(r.text)[3]\n",
    "    career = career[:-2]\n",
    "\n",
    "    career[\"player_name\"] = player_name\n",
    "    career[\"player_id\"] = player_id\n",
    "\n",
    "    career = career[[\"player_id\", \"player_name\", \"CLUB\", \"FROM\", \"TO\", \"FEE\"]].rename(columns = {\"CLUB\": \"club\",\n",
    "                              \"FROM\": \"date_joined\",\n",
    "                              \"TO\": \"date_left\",\n",
    "                              \"FEE\": \"fee\"})\n",
    "    career.columns = career.columns.get_level_values(0)\n",
    "\n",
    "    next_club = pd.DataFrame([{\"player_id\": player_id,\n",
    "                               \"player_name\": player_name,\n",
    "                               \"club\": np.nan,\n",
    "                               \"date_joined\": np.nan,\n",
    "                               \"date_left\": np.nan,\n",
    "                               \"fee\": np.nan}])\n",
    "\n",
    "    first_club = pd.DataFrame([{\"player_id\": player_id,\n",
    "                               \"player_name\": player_name,\n",
    "                               \"club\": np.nan,\n",
    "                               \"date_joined\": np.nan,\n",
    "                               \"date_left\": np.nan,\n",
    "                               \"fee\": np.nan}])\n",
    "    \n",
    "    career = pd.concat([next_club, career, first_club], ignore_index = False)\n",
    "    career = career.to_dict(orient=\"records\")\n",
    "\n",
    "    return career\n",
    "\n",
    "def async_scraping(scrape_function, urls):\n",
    "    threads = min(MAX_THREADS, len(urls))\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor:\n",
    "        results = executor.map(scrape_function, urls)\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_transfer_type(player_name, fee):\n",
    "    if player_name in ['Bailey Passant', 'Cole Stockton', 'Mitch Duggan', 'Ben Jago', 'Ben Maher', 'Danny Harrison', 'Will Vaulks','Mike Jones', 'Richard Hinds', 'Paul Aldridge']:\n",
    "        return \"Trainee\"\n",
    "    elif fee == \"Trainee\":\n",
    "        return \"Trainee\"\n",
    "    elif fee in [\"Free\", \"Signed\", \"Undisc.\"]:\n",
    "        return \"Transfer\"\n",
    "    elif \"£\" in str(fee):\n",
    "        return \"Transfer\"\n",
    "    elif fee == \"Monthly\":\n",
    "        return \"Transfer\"\n",
    "    elif fee == \"Youth\":\n",
    "        return \"Loan\"\n",
    "    else:\n",
    "        return fee\n",
    "\n",
    "def get_home_club(df, player_id, loan_date):\n",
    "    df = df[(df.fee != \"Loan\") & (df.player_id == player_id) & (df.date_joined < loan_date)].copy().reset_index(drop=True)\n",
    "\n",
    "    home_club = df[df.date_joined == df.date_joined.max()].club.values[0]\n",
    "\n",
    "    return(home_club)\n",
    "\n",
    "def date_to_season(date):\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "\n",
    "    if int(month) <= 5:\n",
    "        year1 = year - 1\n",
    "        year2 = str(year)[2:4]\n",
    "        season = f\"{year1}/{year2}\"\n",
    "    elif int(month) > 5:\n",
    "        year1 = year\n",
    "        year2 = year + 1\n",
    "        year2 = str(year2)[2:4]\n",
    "        season = f\"{year1}/{year2}\"\n",
    "\n",
    "    return season\n",
    "\n",
    "def main():\n",
    "    season_urls = get_season_urls()    \n",
    "\n",
    "    player_list = async_scraping(get_player_list, season_urls)\n",
    "    player_list = list(player_list)\n",
    "    player_list = [player for sublist in player_list for player in sublist]\n",
    "    player_list = pd.DataFrame(player_list).drop_duplicates().to_dict(orient=\"records\")\n",
    "\n",
    "    careers = async_scraping(get_player_career, player_list)\n",
    "    careers = list(careers)\n",
    "    careers = [career for sublist in careers for career in sublist]\n",
    "\n",
    "    df = pd.DataFrame(careers).reset_index(drop=True)\n",
    "\n",
    "    df[\"date_joined\"] = pd.to_datetime(df[\"date_joined\"])\n",
    "    df[\"date_left\"] = pd.to_datetime(df[\"date_left\"])\n",
    "\n",
    "    df[\"prev_club\"] = np.nan\n",
    "    df[\"next_club\"] = np.nan\n",
    "    \n",
    "    loans = df[((df[\"club\"] == \"Tranmere\") & (df[\"fee\"] == \"Loan\")) | ((df[\"club\"] != \"Tranmere\") & (df[\"fee\"] != \"Loan\"))].copy()\n",
    "    loans[\"prev_club\"] = loans.club.shift(-1)\n",
    "    loans[\"next_club\"] = loans.club.shift(1)\n",
    "\n",
    "    df.update(loans)\n",
    "\n",
    "    non_loans = df[df[\"fee\"] != \"Loan\"].copy()\n",
    "    non_loans[\"prev_club\"] = non_loans.club.shift(-1)\n",
    "    non_loans[\"next_club\"] = non_loans.club.shift(1)\n",
    "\n",
    "    df.update(non_loans)\n",
    "\n",
    "    multi_loanees = df[(df.fee == \"Loan\") & (df.club == \"Tranmere\")].player_id.value_counts().to_frame().reset_index(drop=False)\n",
    "    multi_loanee_ids = multi_loanees[multi_loanees[\"count\"] > 1][\"player_id\"].values\n",
    "\n",
    "    multi_loans = df[(df.player_id.isin(multi_loanee_ids)) & (df.club == \"Tranmere\") & (df.fee == \"Loan\")].copy()\n",
    "\n",
    "    multi_loans[\"prev_club\"] = multi_loans.apply(lambda x: get_home_club(df, x.player_id, x.date_joined), axis = 1)\n",
    "\n",
    "    df.update(multi_loans)\n",
    "\n",
    "    df[\"prev_club\"] = df.apply(lambda x: \"Trainee\" if x.fee == \"Trainee\" else x.prev_club, axis=1)\n",
    "\n",
    "    df = df[df[\"club\"] == \"Tranmere\"].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    df[\"transfer_type\"] = df.apply(lambda x: get_transfer_type(x.player_name, x.fee), axis=1)\n",
    "\n",
    "    df.loc[df.transfer_type == \"Loan\", \"next_club\"] = np.nan\n",
    "\n",
    "    df[\"fee\"] = df.fee.str.replace(\"£\", \"\").str.replace(\",\", \"\")\n",
    "\n",
    "    df[\"season\"] = df.apply(lambda x: date_to_season(x.date_joined), axis=1)\n",
    "\n",
    "    correct_clubs = pd.DataFrame([\n",
    "        {\"player_id\": \"73901\", \"prev_club\": \"Liverpool\"},\n",
    "        {\"player_id\": \"78589\", \"prev_club\": \"Cardiff City\"},\n",
    "        {\"player_id\": \"115214\", \"prev_club\": \"US Alessandria\"},\n",
    "        {\"player_id\": \"133373\", \"prev_club\": \"Wigan Athletic\"}]\n",
    "    ).sort_values(\"player_id\")\n",
    "\n",
    "    club_updates = df[df.player_id.isin(correct_clubs.player_id)].sort_values(\"player_id\").copy()\n",
    "\n",
    "    club_updates.prev_club = correct_clubs[correct_clubs.player_id.isin(club_updates.player_id)].prev_club.values\n",
    "\n",
    "    df.update(club_updates)\n",
    "\n",
    "    df = df.sort_values(\"player_id\", ascending=False, ignore_index=True)\n",
    "\n",
    "    df[\"surname\"] = df.player_name.str.split(\" \").str[-1]\n",
    "    df = df.sort_values([\"player_name\", \"date_joined\"]).drop(\"surname\", axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = main()\n",
    "df.to_csv(\"./data/player_careers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrape-player-careers-ZQMn66fn-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0494f62c560670d4f9421935ad9b3829278df1552da9c6566360e65838c6e18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
